{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: 98f7c99e-b69e-40e7-b767-fc777db7e0fc\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\nWaiting for session 98f7c99e-b69e-40e7-b767-fc777db7e0fc to get into ready status...\nSession 98f7c99e-b69e-40e7-b767-fc777db7e0fc has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "data_path =\"s3://sai-capstone/housing/prepared/houusing_prepared.csv\" \nhousing_df = spark.read.csv(data_path, header=True, inferSchema=True)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "feature_columns = [col for col in housing_df.columns if col not in [\"median_house_value\", \"ocean_proximity\"]]\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\nhousing_prepared = assembler.transform(housing_df).select(\"features\", \"median_house_value\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "train_data, test_data = housing_prepared.randomSplit([0.8, 0.2], seed=42)\n\n# Train Linear Regression model\nlr = LinearRegression(labelCol=\"median_house_value\", featuresCol=\"features\")\nlr_model = lr.fit(train_data)\nlr_predictions = lr_model.transform(test_data)\nlr_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(lr_predictions)\nprint(f\"Linear Regression RMSE: {lr_rmse}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "Linear Regression RMSE: 67052.72238626775\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "dt = DecisionTreeRegressor(labelCol=\"median_house_value\", featuresCol=\"features\")\ndt_model = dt.fit(train_data)\ndt_predictions = dt_model.transform(test_data)\ndt_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(dt_predictions)\nprint(f\"Decision Tree RMSE: {dt_rmse}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "Decision Tree RMSE: 70010.93504259548\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "rf = RandomForestRegressor(labelCol=\"median_house_value\", featuresCol=\"features\")\nrf_model = rf.fit(train_data)\nrf_predictions = rf_model.transform(test_data)\nrf_rmse = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\").evaluate(rf_predictions)\nprint(f\"Random Forest RMSE: {rf_rmse}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Random Forest RMSE: 66409.40246426823\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "evaluator = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n\nlr_rmse = evaluator.evaluate(lr_model.transform(test_data))\ndt_rmse = evaluator.evaluate(dt_model.transform(test_data))\nrf_rmse = evaluator.evaluate(rf_model.transform(test_data))\n\n# Create a DataFrame to store the RMSE scores\nrmse_scores_df = spark.createDataFrame([\n    (\"Linear Regression\", lr_rmse),\n    (\"Decision Tree\", dt_rmse),\n    (\"Random Forest\", rf_rmse)\n], [\"Model\", \"RMSE\"])\n\n# Specify the output path for storing the RMSE scores\noutput_path = \"s3://sai-capstone/housing/model/rmse_scores.csv\"\n\n# Write the RMSE scores DataFrame to a CSV file\nrmse_scores_df.write.csv(output_path, mode=\"overwrite\", header=True)\n\nprint(\"RMSE scores saved to CSV file.\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "RMSE scores saved to CSV file.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}